# ruby-live-text-to-speech

Ruby (Sinatra) demo app for Deepgram Live Text-to-Speech.

## Architecture

- **Backend:** Ruby (Sinatra) (Ruby) on port 8081
- **Frontend:** Vite + vanilla JS on port 8080 (git submodule: `live-text-to-speech-html`)
- **API type:** WebSocket — `WS /api/live-text-to-speech`
- **Deepgram API:** Live Text-to-Speech (`wss://api.deepgram.com/v1/speak`)
- **Auth:** JWT session tokens via `/api/session` (WebSocket auth uses `access_token.<jwt>` subprotocol)

## Key Files

| File | Purpose |
|------|---------|
| `app.rb` | Main backend — API endpoints and WebSocket proxy |
| `deepgram.toml` | Metadata, lifecycle commands, tags |
| `Makefile` | Standardized build/run targets |
| `sample.env` | Environment variable template |
| `frontend/main.js` | Frontend logic — UI controls, WebSocket connection, audio streaming |
| `frontend/index.html` | HTML structure and UI layout |
| `deploy/Dockerfile` | Production container (Caddy + backend) |
| `deploy/Caddyfile` | Reverse proxy, rate limiting, static serving |

## Quick Start

```bash
# Initialize (clone submodules + install deps)
make init

# Set up environment
test -f .env || cp sample.env .env  # then set DEEPGRAM_API_KEY

# Start both servers
make start
# Backend: http://localhost:8081
# Frontend: http://localhost:8080
```

## Start / Stop

**Start (recommended):**
```bash
make start
```

**Start separately:**
```bash
# Terminal 1 — Backend
bundle exec ruby app.rb

# Terminal 2 — Frontend
cd frontend && corepack pnpm run dev -- --port 8080 --no-open
```

**Stop all:**
```bash
lsof -ti:8080,8081 | xargs kill -9 2>/dev/null
```

**Clean rebuild:**
```bash
rm -rf vendor frontend/node_modules frontend/.vite
make init
```

## Dependencies

- **Backend:** `Gemfile` — Uses Bundler. Sinatra 4.0 needs the `rackup` gem.
- **Frontend:** `frontend/package.json` — Vite dev server
- **Submodules:** `frontend/` (live-text-to-speech-html), `contracts/` (starter-contracts)

Install: `bundle install`
Frontend: `cd frontend && corepack pnpm install`

## API Endpoints

| Endpoint | Method | Auth | Purpose |
|----------|--------|------|---------|
| `/api/session` | GET | None | Issue JWT session token |
| `/api/metadata` | GET | None | Return app metadata (useCase, framework, language) |
| `/api/live-text-to-speech` | WS | JWT | Streams text to Deepgram for real-time audio generation. |

## Customization Guide

### Changing Default Parameters
The WebSocket connection URL passes parameters to Deepgram. Modify these in the backend where the Deepgram URL is constructed:

| Parameter | Default | Options | Effect |
|-----------|---------|---------|--------|
| `model` | `aura-asteria-en` | Any aura-* voice | Voice selection |
| `encoding` | `linear16` | `linear16`, `mp3`, `opus`, `mulaw`, `alaw` | Audio encoding |
| `sample_rate` | `48000` | `8000`-`48000` | Audio sample rate |
| `container` | `none` | `none`, `wav`, `ogg` | Audio container |

**Important:** The frontend audio playback is configured for Linear16 at 48kHz. If you change encoding or sample_rate, you MUST update the frontend's AudioContext and PCM conversion code in `frontend/main.js`.

### WebSocket Message Protocol
The client sends JSON messages to generate audio:
- `{ "type": "Speak", "text": "Hello world" }` — Queue text for synthesis
- `{ "type": "Flush" }` — Signal end of text, flush audio buffer
- `{ "type": "Clear" }` — Cancel pending audio
- `{ "type": "Close" }` — Graceful disconnect

The server streams back binary audio chunks (raw PCM when container=none).

### Changing the Voice Mid-Stream
You can send multiple `Speak` messages with different text. The voice is set at connection time via the `model` parameter. To change voice, you need to reconnect.

### Frontend Audio Pipeline
The frontend converts received Int16 PCM to Float32 for Web Audio API playback. Key constants:
- `BUFFER_AHEAD_TIME` (100ms) — Minimum buffer before starting playback
- Sample rate must match the WebSocket parameter

## Frontend Changes

The frontend is a git submodule from `deepgram-starters/live-text-to-speech-html`. To modify:

1. **Edit files in `frontend/`** — this is the working copy
2. **Test locally** — changes reflect immediately via Vite HMR
3. **Commit in the submodule:** `cd frontend && git add . && git commit -m "feat: description"`
4. **Push the frontend repo:** `cd frontend && git push origin main`
5. **Update the submodule ref:** `cd .. && git add frontend && git commit -m "chore(deps): update frontend submodule"`

**IMPORTANT:** Always edit `frontend/` inside THIS starter directory. The standalone `live-text-to-speech-html/` directory at the monorepo root is a separate checkout.

### Adding a UI Control for a New Feature
1. Add the HTML element in `frontend/index.html` (input, checkbox, dropdown, etc.)
2. Read the value in `frontend/main.js` when making the API call or opening the WebSocket
3. Pass it as a query parameter in the WebSocket URL
4. Handle it in the backend `app.rb` — read the param and pass it to the Deepgram API

## Environment Variables

| Variable | Required | Default | Purpose |
|----------|----------|---------|---------|
| `DEEPGRAM_API_KEY` | Yes | — | Deepgram API key |
| `PORT` | No | `8081` | Backend server port |
| `HOST` | No | `0.0.0.0` | Backend bind address |
| `SESSION_SECRET` | No | — | JWT signing secret (production) |

## Conventional Commits

All commits must follow conventional commits format. Never include `Co-Authored-By` lines for Claude.

```
feat(ruby-live-text-to-speech): add diarization support
fix(ruby-live-text-to-speech): resolve WebSocket close handling
refactor(ruby-live-text-to-speech): simplify session endpoint
chore(deps): update frontend submodule
```

## Testing

```bash
# Run conformance tests (requires app to be running)
make test

# Manual endpoint check
curl -sf http://localhost:8081/api/metadata | python3 -m json.tool
curl -sf http://localhost:8081/api/session | python3 -m json.tool
```
